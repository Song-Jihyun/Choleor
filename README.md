# Choleor
<strong>기존 안무 영상을 다양한 조합으로 교차편집 할 수 있는 기능을 제공해 안부 창작을 돕는 서비스(졸업 프로젝트)</strong><br>
3인 팀으로 1년간 수행한 프로젝트로 저는 포즈수치화 / 영상 교차편집 / 프론트엔드 / DB 구축을 담당했습니다.

## 1. 포즈 수치화
PoseNumericalization.ipynb
### 포즈 수치화의 필요성
![스크린샷(18)](https://user-images.githubusercontent.com/50199997/99183057-870aec00-277c-11eb-9519-d56ec22ac4c9.png)<br><br>
서로 다른 두 영상을 부드럽게 이어붙이기위해서는 영상이 전환되는 부분에서 사람의 위치, 크기, 포즈가 유사해야 합니다. 이 중 포즈의 유사도를 측정하기 위해서 포즈를 수치화 하는 방법을 고안해냈습니다.<br>
포즈 수치화를 위해 필요한 각 관절의 좌표 정보는 openpose를 사용해 분석했습니다.

### Idea 1. Labanotation(무용기보법)
![labanotation](https://user-images.githubusercontent.com/50199997/99185037-7feada80-278a-11eb-86dc-dbe78cae0b73.PNG)<br><br>
labanotation은 무용기보법의 일종으로 왼팔, 오른팔, 왼다리, 오른다리 그리고 몸통이 어느 방향으로 움직이는지를 표기하는 방식으로 구성됩니다. 이런 표기법에서 사지의 위치정보를 각각 표현하는 방법을 착안했고, 몸의 방향, 몸의 높이(서있는지, 앉아있는지, 누워있는지), 손발의 높이, 손발의 좌우 위치를 각각 2bit로 표기하고 이것을 쭉 연결해 하나의 int값으로 표기하는 방법을 만들었습니다.

### Idea 2. Karnaugh Map(카르노 맵)
![카르노맵](https://user-images.githubusercontent.com/50199997/99184994-4dd97880-278a-11eb-9571-ab750c91b6ae.PNG)<br><br>
카르노맵은 보통 논리 회로 설계를 단순화 하기 위해 사용되는 표 입니다. 4x4 카르노맵의 각 행과 열에는 인접한 칸과 1bit씩만 차이가 나도록 2bit 숫자가 할당되어있습니다. 따라서 인접한 칸끼리 XOR연산을 수행하면 결과는 1이 나오고 두 칸 사이의 거리가 멀어질수록 XOR 연산의 결과는 커지게 됩니다. 이런 원리를 포즈 수치화 과정에 반영하면 마찬가지로 XOR연산으로 두 포즈 사이에 얼마나 큰 차이가 있는지를 수치화 할 수 있습니다.

### 포즈 수치화의 예시
![스크린샷(19)](https://user-images.githubusercontent.com/50199997/99183984-4662a100-2783-11eb-9b7c-132d996a247a.png)<br><br>
위 이미지는 왼손과 오른발의 위치를 수치화 한 예시입니다.<br>
손의 경우 어깨를 기준으로 상하/좌우 각각 세 구역으로 나누어 손이 위치해 있는 구역의 값을 할당합니다. 위 이미지의 경우에는 좌측 중앙, 즉 1000의 값을 할당할 수 있습니다.<br>
발의 경우 골만을 기준으로 상하/좌우 각각 세 구역으로 나누어 발이 위치해 있는 구역의 값을 할당합니다. 위 이미지의 경우에는 중앙 하단, 즉 0001의 값을 할당할 수 있습니다.<br><br>

이 외에도 이미지에 나온 포즈 전체를 수치화하면 아래와 같습니다.<br>
방향/높이/ 왼손 /오른손/ 왼발 / 오른발<br>
00 / 00 / 1000 / 1000 / 1001 / 0001<br>
(00001000100010010001)<sub>2</sub> = (34961)<sub>10</sub>

### 포즈 수치화의 한계점
1. 포즈의 깊이를 판단할 수 없습니다. 포즈 수치화를 위한 각 관절의 정보는 openpose를 통해 받아오게 됩니다. 그런데 사람의 몸은 3차원 공간에서 움직이는 것과 다르게 openpose로 얻은 정보는 2차원 정보이기 때문에 발을 앞으로 뻗거나 뒤로 뻗은 동작은 구분하는게 불가능합니다.<br>
2. 몸의 방향을 구별하는데 어려움이 있습니다. openpose에서 앞, 뒤를 구별해 좌표를 출력하기 때문에 정면주시/후면주시는 구별할 수 있지만 좌/우측주시의 경우에는 몸의 좌우중 어느쪽이 카메라와 가까운 곳인지 알 수 없기 때문에 구별할 수 없습니다.<br>
3. 몸의 높이의 경우도 일단은 어깨-골반, 골반-((무릎+발)/2) 이 두 거리의 비율을 기준으로 구별하고 있지만 손/발 측정에 어깨/골반이 기준으로 쓰이는 것 만큼 명확한 기준이 되지는 못하기 때문에 정확도가 많이 떨어지는 결과를 보여줍니다.<br>
4. openpose 자체의 기능이 떨어집니다. 여러 사람이 나오는 영상은 두 사람을 합쳐서 한 사람으로 인식하기도 하고, 학습 데이터에 춤과 같은 다이나믹한 포즈가 없었는지 정적인 포즈에 적용했을 때에 비해서 정확도가 떨어지는 것을 확인할 수 있었습니다.<br><br>

이러한 문제점을 해결하기 위해 결국 자동화된 코드를 통해 수집한 데이터를 수작업으로 검수하는 과정을 거쳐야 했습니다. 이런 검수 과정을 조금이라도 줄이기 위해 다양한 코드를 작성해 사용했습니다. (Tools.ipynb)


## 2. 영상 교차편집
VideoEditor.ipynb
